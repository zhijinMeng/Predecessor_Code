{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 1463/1950 [00:01<00:00, 1291.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length： 8.512 s\n",
      "../dataset/train_wav/41103864_7.6_1_p1_1387.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1950/1950 [00:01<00:00, 1346.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 1950\n",
      "count0: 0\n",
      "count1: 1430\n",
      "count2: 519\n",
      "count3: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the frequency and wav length in record level\n",
    "import contextlib\n",
    "import wave\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "file_path_wav = '../dataset/train_wav/'\n",
    "record_names = [os.path.join(file_path_wav, f) for f in os.listdir(file_path_wav)]\n",
    "record_num = len(record_names)\n",
    "print(record_num)\n",
    "\n",
    "count = 0\n",
    "count0 = 0\n",
    "count1 = 0\n",
    "count2 = 0\n",
    "count3 = 0\n",
    "for i, record_name in enumerate(tqdm(record_names)):\n",
    "    with contextlib.closing(wave.open(record_name, 'r')) as f:\n",
    "        frames = f.getnframes()\n",
    "        rate = f.getframerate()\n",
    "        wav_length = frames / float(rate)\n",
    "        if rate == 8000:\n",
    "            count+=1\n",
    "        else:\n",
    "            print(\"frequency：\",rate,\"HZ\")\n",
    "            print(record_name)\n",
    "            count0+=1            \n",
    "        if wav_length == 9.216:\n",
    "            count1+=1\n",
    "        elif wav_length == 15.36:\n",
    "            count2+=1\n",
    "        else:\n",
    "            print(\"length：\",wav_length,\"s\")\n",
    "            print(record_name)\n",
    "            count3+=1\n",
    "print(\"count: \"+ str(count))\n",
    "print(\"count0: \"+ str(count0))\n",
    "print(\"count1: \"+ str(count1))\n",
    "print(\"count2: \"+ str(count2))\n",
    "print(\"count3: \"+ str(count3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950\n",
      "1755\n",
      "195\n"
     ]
    }
   ],
   "source": [
    "# divide the training and validation set for task2_wav\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "file_path_task2_wav_src = '../dataset/train_wav/'\n",
    "file_path_task2_wav = './task2_wav/train/'\n",
    "save_path_task2_val = './task2_wav/val/'\n",
    "\n",
    "def copy_allfiles(src, dest):\n",
    "    src_files = os.listdir(src)\n",
    "    for file_name in src_files:\n",
    "        full_file_name = os.path.join(src, file_name)\n",
    "        if os.path.isfile(full_file_name):\n",
    "            shutil.copy(full_file_name, dest)\n",
    "\n",
    "copy_allfiles(file_path_task2_wav_src, file_path_task2_wav)\n",
    "\n",
    "record_names = [f for f in os.listdir(file_path_task2_wav)]\n",
    "record_names = sorted(record_names)\n",
    "record_num = len(record_names)\n",
    "print(record_num)\n",
    "\n",
    "for i in range(int(0.9*record_num), record_num):\n",
    "    shutil.move(file_path_task2_wav+record_names[i], save_path_task2_val+record_names[i])\n",
    "\n",
    "record_name_train = [f for f in os.listdir(file_path_task2_wav)]\n",
    "record_num_train = len(record_name_train)\n",
    "print(record_num_train)\n",
    "\n",
    "record_name_val = [s for s in os.listdir(save_path_task2_val)]\n",
    "record_num_val = len(record_name_val)\n",
    "print(record_num_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of task2 wav is: 1755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1755/1755 [00:20<00:00, 84.06it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of task1 wav is: 5914\n",
      "The number of json file is: 1755\n",
      "The number of task11 annotations is: 5914\n",
      "The number of task12 annotations is: 5914\n",
      "The number of task21 annotations is: 1755\n",
      "The number of task22 annotations is: 1755\n"
     ]
    }
   ],
   "source": [
    "# generate the responding training set for task1_wav\n",
    "# generate the responding training annotations for task1_wav and task2_wav\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "file_path_task2_wav = './task2_wav/train/'\n",
    "file_path_json = '../dataset/train_json/'\n",
    "save_path_task1_wav = './task1_wav/train/'\n",
    "save_path_task11_json = './input/train/task11_input.json'\n",
    "save_path_task12_json = './input/train/task12_input.json'\n",
    "save_path_task21_json = './input/train/task21_input.json'\n",
    "save_path_task22_json = './input/train/task22_input.json'\n",
    "\n",
    "record_names = [f for f in os.listdir(file_path_task2_wav)]\n",
    "record_names = sorted(record_names)\n",
    "record_num = len(record_names)\n",
    "print(\"The number of task2 wav is: %d\" % record_num)\n",
    "\n",
    "task11_dic = {}\n",
    "task12_dic = {}\n",
    "task21_dic = {}\n",
    "task22_dic = {}\n",
    "num = 0\n",
    "\n",
    "for i, record_name in enumerate(tqdm(record_names)):\n",
    "    record_json_name = record_name[:-4]+'.json'\n",
    "    record_json = os.path.join(file_path_json, record_json_name)\n",
    "    if os.path.exists(record_json):\n",
    "        with open(record_json, 'rb') as f:\n",
    "            item = json.load(f)\n",
    "            num+=1\n",
    "            # task22 annotations\n",
    "            task22_dic[record_name] = item['record_annotation']\n",
    "            # task21 annotations\n",
    "            if item['record_annotation'] == \"Normal\" or item['record_annotation'] == \"Poor Quality\":\n",
    "                task21_dic[record_name] = item['record_annotation']\n",
    "            else:\n",
    "                task21_dic[record_name] = \"Adventitious\"\n",
    "\n",
    "            if item['event_annotation']:\n",
    "                sound = AudioSegment.from_wav(file_path_task2_wav+record_name)\n",
    "                for j, event_item in enumerate(item['event_annotation']):\n",
    "                    # save task1 wav\n",
    "                    start_time = int(event_item['start'])\n",
    "                    end_time = int(event_item['end'])\n",
    "                    event_sound = sound[start_time:end_time]\n",
    "                    event_name = record_name[:-4]+'_'+str(j)+'.wav'\n",
    "                    event_sound.export(save_path_task1_wav+event_name, format=\"wav\")\n",
    "                    # task12 annotations\n",
    "                    task12_dic[event_name] = event_item['type']\n",
    "                    # task11 annotations\n",
    "                    if event_item['type'] == \"Normal\":\n",
    "                        task11_dic[event_name] = event_item['type']\n",
    "                    else:\n",
    "                        task11_dic[event_name] = \"Adventitious\"\n",
    "    else:\n",
    "        print(record_json_name + \"does not exist!\")\n",
    "\n",
    "event_names = [f for f in os.listdir(save_path_task1_wav)]\n",
    "event_num = len(event_names)\n",
    "print(\"The number of task1 wav is: %d\" % event_num)\n",
    "print(\"The number of json file is: %d\" % num)\n",
    "print(\"The number of task11 annotations is: %d\" % len(task11_dic))\n",
    "print(\"The number of task12 annotations is: %d\" % len(task12_dic))\n",
    "print(\"The number of task21 annotations is: %d\" % len(task21_dic))\n",
    "print(\"The number of task22 annotations is: %d\" % len(task22_dic))\n",
    "\n",
    "# save task11 annotations         \n",
    "with open(save_path_task11_json, 'w') as f11:\n",
    "    json.dump(task11_dic, f11)\n",
    "# save task12 annotations         \n",
    "with open(save_path_task12_json, 'w') as f12:\n",
    "    json.dump(task12_dic, f12)\n",
    "# save task21 annotations         \n",
    "with open(save_path_task21_json, 'w') as f21:\n",
    "    json.dump(task21_dic, f21)\n",
    "# save task22 annotations         \n",
    "with open(save_path_task22_json, 'w') as f22:\n",
    "    json.dump(task22_dic, f22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of task2 wav is: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:02<00:00, 84.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1.json does not exist!\n",
      "test2.json does not exist!\n",
      "The number of task1 wav is: 742\n",
      "The number of json file is: 193\n",
      "The number of task11 annotations is: 742\n",
      "The number of task12 annotations is: 742\n",
      "The number of task21 annotations is: 193\n",
      "The number of task22 annotations is: 193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# generate the responding validation set for task1_wav\n",
    "# generate the responding validation annotations for task1_wav and task2_wav\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "file_path_task2_wav = './task2_wav/val/'\n",
    "file_path_json = '../dataset/train_json/'\n",
    "save_path_task1_wav = './task1_wav/val/'\n",
    "save_path_task11_json = './input/val/task11_input.json'\n",
    "save_path_task12_json = './input/val/task12_input.json'\n",
    "save_path_task21_json = './input/val/task21_input.json'\n",
    "save_path_task22_json = './input/val/task22_input.json'\n",
    "\n",
    "record_names = [f for f in os.listdir(file_path_task2_wav)]\n",
    "record_names = sorted(record_names)\n",
    "record_num = len(record_names)\n",
    "print(\"The number of task2 wav is: %d\" % record_num)\n",
    "\n",
    "task11_dic = {}\n",
    "task12_dic = {}\n",
    "task21_dic = {}\n",
    "task22_dic = {}\n",
    "num = 0\n",
    "\n",
    "for i, record_name in enumerate(tqdm(record_names)):\n",
    "    record_json_name = record_name[:-4]+'.json'\n",
    "    record_json = os.path.join(file_path_json, record_json_name)\n",
    "    if os.path.exists(record_json):\n",
    "        with open(record_json, 'rb') as f:\n",
    "            item = json.load(f)\n",
    "            num+=1\n",
    "            # task22 annotations\n",
    "            task22_dic[record_name] = item['record_annotation']\n",
    "            # task21 annotations\n",
    "            if item['record_annotation'] == \"Normal\" or item['record_annotation'] == \"Poor Quality\":\n",
    "                task21_dic[record_name] = item['record_annotation']\n",
    "            else:\n",
    "                task21_dic[record_name] = \"Adventitious\"\n",
    "\n",
    "            if item['event_annotation']:\n",
    "                sound = AudioSegment.from_wav(file_path_task2_wav+record_name)\n",
    "                for j, event_item in enumerate(item['event_annotation']):\n",
    "                    # save task1 wav\n",
    "                    start_time = int(event_item['start'])\n",
    "                    end_time = int(event_item['end'])\n",
    "                    event_sound = sound[start_time:end_time]\n",
    "                    event_name = record_name[:-4]+'_'+str(j)+'.wav'\n",
    "                    event_sound.export(save_path_task1_wav+event_name, format=\"wav\")\n",
    "                    # task12 annotations\n",
    "                    task12_dic[event_name] = event_item['type']\n",
    "                    # task11 annotations\n",
    "                    if event_item['type'] == \"Normal\":\n",
    "                        task11_dic[event_name] = event_item['type']\n",
    "                    else:\n",
    "                        task11_dic[event_name] = \"Adventitious\"\n",
    "    else:\n",
    "        print(record_json_name + \" does not exist!\")\n",
    "\n",
    "event_names = [f for f in os.listdir(save_path_task1_wav)]\n",
    "event_num = len(event_names)\n",
    "print(\"The number of task1 wav is: %d\" % event_num)\n",
    "print(\"The number of json file is: %d\" % num)\n",
    "print(\"The number of task11 annotations is: %d\" % len(task11_dic))\n",
    "print(\"The number of task12 annotations is: %d\" % len(task12_dic))\n",
    "print(\"The number of task21 annotations is: %d\" % len(task21_dic))\n",
    "print(\"The number of task22 annotations is: %d\" % len(task22_dic))\n",
    "\n",
    "# save task11 annotations         \n",
    "with open(save_path_task11_json, 'w') as f11:\n",
    "    json.dump(task11_dic, f11)\n",
    "# save task12 annotations         \n",
    "with open(save_path_task12_json, 'w') as f12:\n",
    "    json.dump(task12_dic, f12)\n",
    "# save task21 annotations         \n",
    "with open(save_path_task21_json, 'w') as f21:\n",
    "    json.dump(task21_dic, f21)\n",
    "# save task22 annotations         \n",
    "with open(save_path_task22_json, 'w') as f22:\n",
    "    json.dump(task22_dic, f22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5914/5914 [00:00<00:00, 1279405.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 4555\n",
      "The number of class \"Adventitious\" is: 1359\n",
      "The number of all classes is: 5914\n",
      "The task11 class weight is: [1.2983534577387486, 4.351729212656365]\n",
      "tensor([1.2984, 4.3517])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in training set of task11 \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "\n",
    "file_path = './input/train/task11_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"Adventitious\":\n",
    "            num_1+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"Adventitious\\\" is: %d\" % num_1)\n",
    "print(\"The number of all classes is: %d\" % num)\n",
    "task11_class_weight = []\n",
    "task11_class_weight.append(num/num_0)\n",
    "task11_class_weight.append(num/num_1)\n",
    "print(f'The task11 class weight is: {task11_class_weight}')\n",
    "class_weights = torch.FloatTensor(task11_class_weight)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [00:00<00:00, 916733.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 605\n",
      "The number of class \"Adventitious\" is: 139\n",
      "The number of all classes is: 744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in validation set of task11 \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "file_path = './input/val/task11_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"Adventitious\":\n",
    "            num_1+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"Adventitious\\\" is: %d\" % num_1)\n",
    "print(\"The number of all classes is: %d\" % num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5914/5914 [00:00<00:00, 605549.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 4555\n",
      "The number of class \"Rhonchi\" is: 39\n",
      "The number of class \"Wheeze\" is: 400\n",
      "The number of class \"Stridor\" is: 14\n",
      "The number of class \"Coarse Crackle\" is: 49\n",
      "The number of class \"Fine Crackle\" is: 830\n",
      "The number of class \"Wheeze+Crackle\" is: 27\n",
      "The number of all classes is: 5914\n",
      "The task12 class weight is: [1.2983534577387486, 151.64102564102564, 14.785, 422.42857142857144, 120.6938775510204, 7.125301204819277, 219.03703703703704]\n",
      "tensor([  1.2984, 151.6410,  14.7850, 422.4286, 120.6939,   7.1253, 219.0370])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in training set of task12\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "file_path = './input/train/task12_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "num_2 = 0\n",
    "num_3 = 0\n",
    "num_4 = 0\n",
    "num_5 = 0\n",
    "num_6 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"Rhonchi\":\n",
    "            num_1+=1\n",
    "        elif value == \"Wheeze\":\n",
    "            num_2+=1\n",
    "        elif value == \"Stridor\":\n",
    "            num_3+=1\n",
    "        elif value == \"Coarse Crackle\":\n",
    "            num_4+=1\n",
    "        elif value == \"Fine Crackle\":\n",
    "            num_5+=1\n",
    "        elif value == \"Wheeze+Crackle\":\n",
    "            num_6+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1 + num_2 + num_3 + num_4 + num_5 + num_6\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"Rhonchi\\\" is: %d\" % num_1)\n",
    "print(\"The number of class \\\"Wheeze\\\" is: %d\" % num_2)\n",
    "print(\"The number of class \\\"Stridor\\\" is: %d\" % num_3)\n",
    "print(\"The number of class \\\"Coarse Crackle\\\" is: %d\" % num_4)\n",
    "print(\"The number of class \\\"Fine Crackle\\\" is: %d\" % num_5)\n",
    "print(\"The number of class \\\"Wheeze+Crackle\\\" is: %d\" % num_6)\n",
    "print(\"The number of all classes is: %d\" % num)\n",
    "task12_class_weight = []\n",
    "task12_class_weight.append(num/num_0)\n",
    "task12_class_weight.append(num/num_1)\n",
    "task12_class_weight.append(num/num_2)\n",
    "task12_class_weight.append(num/num_3)\n",
    "task12_class_weight.append(num/num_4)\n",
    "task12_class_weight.append(num/num_5)\n",
    "task12_class_weight.append(num/num_6)\n",
    "print(f'The task12 class weight is: {task12_class_weight}')\n",
    "class_weights = torch.FloatTensor(task12_class_weight)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 744/744 [00:00<00:00, 643414.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 605\n",
      "The number of class \"Rhonchi\" is: 0\n",
      "The number of class \"Wheeze\" is: 52\n",
      "The number of class \"Stridor\" is: 1\n",
      "The number of class \"Coarse Crackle\" is: 0\n",
      "The number of class \"Fine Crackle\" is: 83\n",
      "The number of class \"Wheeze+Crackle\" is: 3\n",
      "The number of all classes is: 744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in validation set of task12\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "file_path = './input/val/task12_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "num_2 = 0\n",
    "num_3 = 0\n",
    "num_4 = 0\n",
    "num_5 = 0\n",
    "num_6 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"Rhonchi\":\n",
    "            num_1+=1\n",
    "        elif value == \"Wheeze\":\n",
    "            num_2+=1\n",
    "        elif value == \"Stridor\":\n",
    "            num_3+=1\n",
    "        elif value == \"Coarse Crackle\":\n",
    "            num_4+=1\n",
    "        elif value == \"Fine Crackle\":\n",
    "            num_5+=1\n",
    "        elif value == \"Wheeze+Crackle\":\n",
    "            num_6+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1 + num_2 + num_3 + num_4 + num_5 + num_6\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"Rhonchi\\\" is: %d\" % num_1)\n",
    "print(\"The number of class \\\"Wheeze\\\" is: %d\" % num_2)\n",
    "print(\"The number of class \\\"Stridor\\\" is: %d\" % num_3)\n",
    "print(\"The number of class \\\"Coarse Crackle\\\" is: %d\" % num_4)\n",
    "print(\"The number of class \\\"Fine Crackle\\\" is: %d\" % num_5)\n",
    "print(\"The number of class \\\"Wheeze+Crackle\\\" is: %d\" % num_6)\n",
    "print(\"The number of all classes is: %d\" % num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1755/1755 [00:00<00:00, 1072719.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 1164\n",
      "The number of class \"Adventitious\" is: 436\n",
      "The number of class \"Poor Quality\" is: 155\n",
      "The number of all classes is: 1755\n",
      "The task21 class weight is: [1.5077319587628866, 4.025229357798165, 11.32258064516129]\n",
      "tensor([ 1.5077,  4.0252, 11.3226])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in training set of task21 \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "file_path = './input/train/task21_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "num_2 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"Adventitious\":\n",
    "            num_1+=1\n",
    "        elif value == \"Poor Quality\":\n",
    "            num_2+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1 + num_2\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"Adventitious\\\" is: %d\" % num_1)\n",
    "print(\"The number of class \\\"Poor Quality\\\" is: %d\" % num_2)\n",
    "print(\"The number of all classes is: %d\" % num)\n",
    "task21_class_weight = []\n",
    "task21_class_weight.append(num/num_0)\n",
    "task21_class_weight.append(num/num_1)\n",
    "task21_class_weight.append(num/num_2)\n",
    "print(f'The task21 class weight is: {task21_class_weight}')\n",
    "class_weights = torch.FloatTensor(task21_class_weight)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:00<00:00, 679874.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 140\n",
      "The number of class \"Adventitious\" is: 34\n",
      "The number of class \"Poor Quality\" is: 21\n",
      "The number of all classes is: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in validation set of task21 \n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "file_path = './input/val/task21_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "num_2 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"Adventitious\":\n",
    "            num_1+=1\n",
    "        elif value == \"Poor Quality\":\n",
    "            num_2+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1 + num_2\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"Adventitious\\\" is: %d\" % num_1)\n",
    "print(\"The number of class \\\"Poor Quality\\\" is: %d\" % num_2)\n",
    "print(\"The number of all classes is: %d\" % num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1755/1755 [00:00<00:00, 1191679.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 1164\n",
      "The number of class \"CAS\" is: 124\n",
      "The number of class \"DAS\" is: 234\n",
      "The number of class \"CAS & DAS\" is: 78\n",
      "The number of class \"Poor Quality\" is: 155\n",
      "The number of all classes is: 1755\n",
      "The task22 class weight is: [1.5077319587628866, 14.153225806451612, 7.5, 22.5, 11.32258064516129]\n",
      "tensor([ 1.5077, 14.1532,  7.5000, 22.5000, 11.3226])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in training set of task22\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "file_path = './input/train/task22_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "num_2 = 0\n",
    "num_3 = 0\n",
    "num_4 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"CAS\":\n",
    "            num_1+=1\n",
    "        elif value == \"DAS\":\n",
    "            num_2+=1\n",
    "        elif value == \"CAS & DAS\":\n",
    "            num_3+=1\n",
    "        elif value == \"Poor Quality\":\n",
    "            num_4+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1 + num_2 + num_3 + num_4\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"CAS\\\" is: %d\" % num_1)\n",
    "print(\"The number of class \\\"DAS\\\" is: %d\" % num_2)\n",
    "print(\"The number of class \\\"CAS & DAS\\\" is: %d\" % num_3)\n",
    "print(\"The number of class \\\"Poor Quality\\\" is: %d\" % num_4)\n",
    "print(\"The number of all classes is: %d\" % num)\n",
    "task22_class_weight = []\n",
    "task22_class_weight.append(num/num_0)\n",
    "task22_class_weight.append(num/num_1)\n",
    "task22_class_weight.append(num/num_2)\n",
    "task22_class_weight.append(num/num_3)\n",
    "task22_class_weight.append(num/num_4)\n",
    "print(f'The task22 class weight is: {task22_class_weight}')\n",
    "class_weights = torch.FloatTensor(task22_class_weight)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:00<00:00, 329528.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of class \"Normal\" is: 140\n",
      "The number of class \"CAS\" is: 10\n",
      "The number of class \"DAS\" is: 15\n",
      "The number of class \"CAS & DAS\" is: 9\n",
      "The number of class \"Poor Quality\" is: 21\n",
      "The number of all classes is: 195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate the number of all classes in validation set of task22\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "file_path = './input/val/task22_input.json'\n",
    "num_0 = 0\n",
    "num_1 = 0\n",
    "num_2 = 0\n",
    "num_3 = 0\n",
    "num_4 = 0\n",
    "\n",
    "with open(file_path, 'rb') as f:\n",
    "    items = json.load(f)\n",
    "    for value in tqdm(items.values()):\n",
    "        if value == \"Normal\":\n",
    "            num_0+=1\n",
    "        elif value == \"CAS\":\n",
    "            num_1+=1\n",
    "        elif value == \"DAS\":\n",
    "            num_2+=1\n",
    "        elif value == \"CAS & DAS\":\n",
    "            num_3+=1\n",
    "        elif value == \"Poor Quality\":\n",
    "            num_4+=1\n",
    "        else:\n",
    "            print(value)\n",
    "\n",
    "num = num_0 + num_1 + num_2 + num_3 + num_4\n",
    "print(\"The number of class \\\"Normal\\\" is: %d\" % num_0)\n",
    "print(\"The number of class \\\"CAS\\\" is: %d\" % num_1)\n",
    "print(\"The number of class \\\"DAS\\\" is: %d\" % num_2)\n",
    "print(\"The number of class \\\"CAS & DAS\\\" is: %d\" % num_3)\n",
    "print(\"The number of class \\\"Poor Quality\\\" is: %d\" % num_4)\n",
    "print(\"The number of all classes is: %d\" % num)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e4fd8e7fe2dfc368e3fce20a73cc0f3963c555ec65bd7ed536983d101190bb17"
  },
  "kernelspec": {
   "display_name": "Python 3.7.12 ('seg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
